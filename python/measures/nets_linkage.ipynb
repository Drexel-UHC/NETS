{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2024-04-17 15:36:06.193513\n"
     ]
    }
   ],
   "source": [
    "# START SCRIPT TIMER\n",
    "print(f\"Start Time: {datetime.now()}\")\n",
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD USER FILE PATHS\n",
    "\n",
    "# BEDDN spatial file used to create generate near table\n",
    "dunslocs_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Geodatabases\\NETS2022_locs.gdb\\DunsLocations20231130_v2'\n",
    "\n",
    "# participant location file used to create generate near table\n",
    "mesa_locs_file = r'X:\\AddressGeocoding\\From_MESA_Air\\Data\\MESAAIR_locs.gdb\\mesa_locs_aeac_zcta10'\n",
    "\n",
    "# generate near table\n",
    "near_table_file = r'X:\\AddressGeocoding\\From_MESA_Air\\Data\\Temp\\scratch\\NETS_linkage_test.gdb\\mesa_nets_linkage_test'\n",
    "\n",
    "classifiedlong_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\ClassifiedLong20231127.txt'\n",
    "dunsmove_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\DunsMove20231201.txt'\n",
    "cat_descriptions_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\CategoryDescriptions20231127.txt'\n",
    "xwalk_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\BG_CC_TC_Xwalk20231023.txt'\n",
    "output_folder = r'D:\\scratch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Food', 'Healthcare', 'Physical Activity', 'Social', 'Cognitive Enrichment', 'Financial', 'Alcohol, Tobacco, Marijuana, Firearm', 'Walking', 'Transportation', 'Disaster/Construction']\n"
     ]
    }
   ],
   "source": [
    "# USER INPUTS\n",
    "\n",
    "# read in descriptions file, get list of domains\n",
    "desc = pd.read_csv(cat_descriptions_file, sep='\\t')\n",
    "domlist = list(desc['Domain'].unique())\n",
    "print(domlist)\n",
    "\n",
    "# provide list of categories by entire domain\n",
    "domains = ['Financial']\n",
    "\n",
    "# provide list of individual categories\n",
    "categories = ['DLR', 'CMN', 'GRY']\n",
    "\n",
    "# provide list of year(s)\n",
    "years = [2000, 2005]\n",
    "\n",
    "# use hierarchy? True or False\n",
    "hierarchy = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r\"F:\\Arc_Projects\\NETS_test_linkage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CONVERT FC TABLE TO PANDAS DF\n",
    "\n",
    "# define function to convert fc table to pandas dataframe\n",
    "def table_to_data_frame(in_table, input_fields=None, where_clause=None):\n",
    "    \"\"\"Function will convert an arcgis table into a pandas dataframe with an object ID index, and the selected\n",
    "    input fields using an arcpy.da.SearchCursor.\"\"\"\n",
    "    OIDFieldName = arcpy.Describe(in_table).OIDFieldName\n",
    "    if input_fields:\n",
    "        final_fields = [OIDFieldName] + input_fields\n",
    "    else:\n",
    "        final_fields = [field.name for field in arcpy.ListFields(in_table)]\n",
    "    data = [row for row in arcpy.da.SearchCursor(in_table, final_fields, where_clause=where_clause)]\n",
    "    fc_dataframe = pd.DataFrame(data, columns=final_fields)\n",
    "    fc_dataframe = fc_dataframe.set_index(OIDFieldName, drop=True)\n",
    "    return fc_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LOAD NEAR TABLE AND MESA LOCS THEN MERGE\n",
    "\n",
    "near_df = table_to_data_frame(near_table_file, input_fields=['IN_FID', 'NEAR_FID', 'NEAR_DIST'])\n",
    "mesa_locs = table_to_data_frame(mesa_locs_file, input_fields=['LOCID_DREXEL', 'UHCMatchCodeRank'])\n",
    "\n",
    "# merge participant location unique ids and uhcmatchcoderank to near table\n",
    "join_mesa = (near_df\n",
    "              .merge(mesa_locs, how='left', left_on='IN_FID', right_on='OBJECTID')\n",
    "              .drop(columns=['IN_FID'])\n",
    "              .rename(columns={'UHCMatchCodeRank': 'UHCMatchCodeRank_MESA'})\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DUNS LOCS THEN MERGE\n",
    "\n",
    "dunslocs = table_to_data_frame(dunslocs_file, input_fields=['AddressId', 'UHCMatchCodeRank'])\n",
    "\n",
    "# merge beddn addressids and uhcmatchcoderank\n",
    "join_addressid = (join_mesa\n",
    "                  .merge(dunslocs, how='left', left_on='NEAR_FID', right_on='OBJECTID')\n",
    "                  .drop(columns=['NEAR_FID'])\n",
    "                  .rename(columns={'UHCMatchCodeRank': 'UHCMatchCodeRank_NETS'})\n",
    "                 )\n",
    "\n",
    "# check shape (rows, cols) of dataframe\n",
    "join_addressid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBSET LIST OF BEDDN CATEGORIES\n",
    "\n",
    "# grab all categories in chosen domain(s)\n",
    "domain_cats = desc['Category'].loc[desc['Domain'].isin(domains)]  \n",
    "all_cats = list(domain_cats)\n",
    "\n",
    "# grab all additional categories\n",
    "[all_cats.append(category) for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN CLASSIFIED LONG AND SUBSET BY CATEGORY\n",
    "# this isn't really a part of this workflow. let's get all categories for each participant location \n",
    "\n",
    "# classlong = pd.read_csv(classifiedlong_file, sep='\\t', usecols=['DunsYear','BaseGroup'])\n",
    "\n",
    "# # subset for provided categories\n",
    "# measures = classlong.loc[classlong['BaseGroup'].isin(all_cats)]\n",
    "# del classlong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% READ IN DUNSMOVE AND SUBSET BY YEAR\n",
    "\n",
    "# merge in dunsmove columns\n",
    "dunsmove = pd.read_csv(dunsmove_file, sep='\\t', usecols=['DunsYear', 'DunsMove', 'AddressID', 'Year'], dtype={'Year':int})\n",
    "measures = measures.merge(dunsmove, how='left', on='DunsYear')\n",
    "del dunsmove\n",
    "\n",
    "# subset file for years requested\n",
    "measures = measures.loc[measures['Year'].isin(years)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% JOIN LOCATION INFO\n",
    "\n",
    "dunslocs = pd.read_csv(dunslocation_file, sep='\\t', usecols=['AddressID', 'DisplayX', 'DisplayY', 'UHCMatchCodeRank'])\n",
    "\n",
    "measures = measures.merge(dunslocs, how='left', on='AddressID')\n",
    "del dunslocs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END SCRIPT TIMER \n",
    "toc = time.perf_counter()\n",
    "t = toc - tic\n",
    "print(f'total time: {round(t/60, 2)} minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
