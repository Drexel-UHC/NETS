{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2024-04-17 17:24:26.103929\n"
     ]
    }
   ],
   "source": [
    "# START SCRIPT TIMER\n",
    "print(f\"Start Time: {datetime.now()}\")\n",
    "tic = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD USER FILE PATHS\n",
    "\n",
    "# BEDDN spatial file used to create generate near table\n",
    "dunslocs_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Geodatabases\\NETS2022_locs.gdb\\DunsLocations20231130_v2'\n",
    "\n",
    "# participant location file used to create generate near table\n",
    "mesa_locs_file = r'X:\\AddressGeocoding\\From_MESA_Air\\Data\\MESAAIR_locs.gdb\\mesa_locs_aeac_zcta10'\n",
    "\n",
    "# generate near table\n",
    "near_table_file = r'X:\\AddressGeocoding\\From_MESA_Air\\Data\\Temp\\scratch\\NETS_linkage_test.gdb\\mesa_nets_linkage_test_sample'\n",
    "\n",
    "classifiedlong_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\ClassifiedLong20231127.txt'\n",
    "dunsmove_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\DunsMove20231201.txt'\n",
    "cat_descriptions_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\CategoryDescriptions20231127.txt'\n",
    "xwalk_file = r'Z:\\UHC_Data\\NETS_UHC\\NETS2022\\Data\\Final\\BG_CC_TC_Xwalk20231023.txt'\n",
    "output_folder = r'D:\\scratch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Food', 'Healthcare', 'Physical Activity', 'Social', 'Cognitive Enrichment', 'Financial', 'Alcohol, Tobacco, Marijuana, Firearm', 'Walking', 'Transportation', 'Disaster/Construction']\n"
     ]
    }
   ],
   "source": [
    "# USER INPUTS\n",
    "\n",
    "# provide list of year(s)\n",
    "years = [2000, 2005]\n",
    "\n",
    "# use hierarchy? True or False\n",
    "hierarchy = True\n",
    "\n",
    "# limit categories? True or False\n",
    "limit_cats = False\n",
    "\n",
    "# if True, pick categories:\n",
    "\n",
    "# print list of domains\n",
    "desc = pd.read_csv(cat_descriptions_file, sep='\\t')\n",
    "domlist = list(desc['Domain'].unique())\n",
    "print(domlist)\n",
    "\n",
    "# provide list of categories by entire domain (optional):\n",
    "domains = ['Financial']\n",
    "\n",
    "# provide list of individual categories (optional):\n",
    "categories = ['DLR', 'CMN', 'GRY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r\"F:\\Arc_Projects\\NETS_test_linkage\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CONVERT FC TABLE TO PANDAS DF\n",
    "\n",
    "# define function to convert fc table to pandas dataframe\n",
    "def table_to_data_frame(in_table, input_fields=None, where_clause=None):\n",
    "    \"\"\"Function will convert an arcgis table into a pandas dataframe with an object ID index, and the selected\n",
    "    input fields using an arcpy.da.SearchCursor.\"\"\"\n",
    "    OIDFieldName = arcpy.Describe(in_table).OIDFieldName\n",
    "    if input_fields:\n",
    "        final_fields = [OIDFieldName] + input_fields\n",
    "    else:\n",
    "        final_fields = [field.name for field in arcpy.ListFields(in_table)]\n",
    "    data = [row for row in arcpy.da.SearchCursor(in_table, final_fields, where_clause=where_clause)]\n",
    "    fc_dataframe = pd.DataFrame(data, columns=final_fields)\n",
    "    fc_dataframe = fc_dataframe.set_index(OIDFieldName, drop=True)\n",
    "    return fc_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LOAD NEAR TABLE AND MESA LOCS THEN MERGE\n",
    "\n",
    "near_df = table_to_data_frame(near_table_file, input_fields=['IN_FID', 'NEAR_FID', 'NEAR_DIST'])\n",
    "mesa_locs = table_to_data_frame(mesa_locs_file, input_fields=['LOCID_DREXEL', 'UHCMatchCodeRank'])\n",
    "\n",
    "# merge participant location unique ids and uhcmatchcoderank to near table\n",
    "join_mesa = (near_df\n",
    "              .merge(mesa_locs, how='left', left_on='IN_FID', right_on='OBJECTID')\n",
    "              .drop(columns=['IN_FID'])\n",
    "              .rename(columns={'UHCMatchCodeRank': 'UHCMatchCodeRank_MESA'})\n",
    "             )\n",
    "del mesa_locs, near_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23178595, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOAD DUNS LOCS THEN MERGE\n",
    "\n",
    "dunslocs = table_to_data_frame(dunslocs_file, input_fields=['AddressID', 'UHCMatchCodeRank'])\n",
    "\n",
    "# merge beddn addressids and uhcmatchcoderank\n",
    "join_addressid = (join_mesa\n",
    "                  .merge(dunslocs, how='left', left_on='NEAR_FID', right_on='OBJECTID')\n",
    "                  .drop(columns=['NEAR_FID'])\n",
    "                  .rename(columns={'UHCMatchCodeRank': 'UHCMatchCodeRank_NETS'})\n",
    "                 )\n",
    "del join_mesa, dunslocs\n",
    "\n",
    "# check shape (rows, cols) of dataframe\n",
    "join_addressid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SUBSET LIST OF BEDDN CATEGORIES\n",
    "\n",
    "# grab all categories in chosen domain(s)\n",
    "domain_cats = desc['Category'].loc[desc['Domain'].isin(domains)]  \n",
    "all_cats = list(domain_cats)\n",
    "\n",
    "# grab all additional categories\n",
    "[all_cats.append(category) for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['AddressId']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "In  \u001b[0;34m[36]\u001b[0m:\nLine \u001b[0;34m2\u001b[0m:     dunsmove = pd.read_csv(dunsmove_file, sep=\u001b[33m'\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, usecols=[\u001b[33m'\u001b[39;49;00m\u001b[33mDunsYear\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mDunsMove\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mAddressId\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mYear\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], dtype={\u001b[33m'\u001b[39;49;00m\u001b[33mYear\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\u001b[36mint\u001b[39;49;00m})\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m, in \u001b[0;32mread_csv\u001b[0m:\nLine \u001b[0;34m912\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m _read(filepath_or_buffer, kwds)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m, in \u001b[0;32m_read\u001b[0m:\nLine \u001b[0;34m577\u001b[0m:   parser = TextFileReader(filepath_or_buffer, **kwds)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m, in \u001b[0;32m__init__\u001b[0m:\nLine \u001b[0;34m1407\u001b[0m:  \u001b[36mself\u001b[39;49;00m._engine = \u001b[36mself\u001b[39;49;00m._make_engine(f, \u001b[36mself\u001b[39;49;00m.engine)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m, in \u001b[0;32m_make_engine\u001b[0m:\nLine \u001b[0;34m1679\u001b[0m:  \u001b[34mreturn\u001b[39;49;00m mapping[engine](f, **\u001b[36mself\u001b[39;49;00m.options)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m, in \u001b[0;32m__init__\u001b[0m:\nLine \u001b[0;34m140\u001b[0m:   \u001b[36mself\u001b[39;49;00m._validate_usecols_names(usecols, \u001b[36mself\u001b[39;49;00m.orig_names)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m, in \u001b[0;32m_validate_usecols_names\u001b[0m:\nLine \u001b[0;34m958\u001b[0m:   \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['AddressId']\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# READ IN DUNSMOVE AND SUBSET BY YEAR\n",
    "dunsmove = pd.read_csv(dunsmove_file, sep='\\t', usecols=['DunsYear', 'DunsMove', 'AddressID', 'Year'], dtype={'Year':int})\n",
    "\n",
    "# subset dunsmove for years requested\n",
    "dunsmove = dunsmove.loc[dunsmove['Year'].isin(years)] \n",
    "\n",
    "# merge in dunsmove columns\n",
    "join_dunsmove = join_addressid.merge(dunsmove, how='left', on='AddressID')\n",
    "del dunsmove, join_addressid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN CLASSIFIED LONG AND SUBSET BY CATEGORY IF APPLICABLE\n",
    "classlong = pd.read_csv(classifiedlong_file, sep='\\t', usecols=['DunsYear','BaseGroup'])\n",
    "\n",
    "# subset for provided categories\n",
    "if limit_cats == True:\n",
    "    classlong = classlong.loc[classlong['BaseGroup'].isin(all_cats)]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE BASE GROUP (CLASSIFIED) DATA \n",
    "join_classlong = join_dunsmove.merge(classlong, how='left', on='DunsYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END SCRIPT TIMER \n",
    "toc = time.perf_counter()\n",
    "t = toc - tic\n",
    "print(f'total time: {round(t/60, 2)} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
